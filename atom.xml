<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Philippe Desjardins-Proulx's blog</title>
    <link href="http://phdp.github.io//atom.xml" rel="self" />
    <link href="http://phdp.github.io/" />
    <id>http://phdp.github.io//atom.xml</id>
    <author>
        <name>Philippe Desjardins-Proulx</name>
        <email>philippe.d.proulx@gmail.com</email>
    </author>
    <updated>2018-04-17T00:00:00Z</updated>
    <entry>
    <title>A crash course in second-order logic</title>
    <link href="http://phdp.github.io//posts/2018-04-17-sol.html" />
    <id>http://phdp.github.io//posts/2018-04-17-sol.html</id>
    <published>2018-04-17T00:00:00Z</published>
    <updated>2018-04-17T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>A crash course in second-order logic</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="A crash course in second-order logic" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2018.04.17
</p>

<p><a href='2015-07-13-fol.html'>I previously wrote a very short introduction
to first-order logic.</a> That introduction ignored many important questions,
like how to perform inference, and focused only on defining first-order logic
and providing some examples of what it could express. I wrote this intro
because first-order logic is a central player in researchers' effort to combine
symbolic with probabilistic representations, but a natural question arise: why
<b>first</b> order? Is there zeroth-order, second-order, higher-order? The
answers are: yes, yes, and yes, and here I'll briefly explain what second-order
and zeroth-order logics are.</p>

<p>First-order logic is a powerful symbolic representation for mathematical
ideas. Take Catalan's conjecture, explained in detail by <a
href='https://www.youtube.com/watch?v=Us-__MukH9I'>Holly Krieger in this
numberphile video</a>. In 1842, Eugène Charles Catalan wondered whether \((2^3 =
8, 3^2 = 9)\) was the only pair of consecutive perfect powers, i.e. the
power of a natural number greater than one such as \(2^3\), \(5^2\),
\(9^{15}\), ... We can formalize this conjecture in first-order logic:</p>

\[\exists! x, y, a, b \in \mathbb{N}: x > 0 \land y > 0 \land a > 1 \land b > 1 \land y^b = x^a + 1.\]

<p>\(\exists!\) is the unique quantifier ("there exists only one"), and \(x \in
\mathbb{N}\) reads "x belongs to the natural numbers". Preda Mihăilescu proved
it in 2002.</p>

<p>So what makes this formula <b>first</b> order? It means the formula only
quantifies over individual elements. In the previous formula, the variables
\(x, y, a, b\) ranged over individual elements (natural numbers). We call these
individual variables. They could also range over cities, presidential
candidates, species, complex numbers, vectors, etc etc, but they cannot, say,
range over functions or sets of elements. In a nutshell: second-order logic is
exactly like first-order logic in every way (same connectives, same predicates,
same quantifiers), but it allows quantification over sets, predicates, and
functions. It adds function variables and predicate variables (with sets being,
in essence, predicates). And that's it. For example, an important idea in
classical logic is that something either is or isn't in a set. It can be
written in second-order logic as:</p>

\[\forall x, S: x \in S \veebar x \not \in S\]

<p>with \(\veebar\) <a href='2015-07-13-fol.html'>being the <i>exclusive or</i>
symbol</a> and \(\in\) being the "belongs to" predicate. Here, \(x\) is an
individual variable, but \(S\) is a predicate variable, it represents sets, not
individual elements. You could definitely write specific versions of this
idea in first-order logic by replacing the predicate variable \(S\) with
specific sets:</p>

\[\forall x: x \in \mathbb{N} \veebar x \not \in \mathbb{N}.\]
\[\forall x: x \in \mathbb{C} \veebar x \not \in \mathbb{C}.\]
\[\forall x: IsFromVenus(x) \veebar \neg IsFromVenus(x).\]

<p>All these formulas are first-order, since they only quantify over individual
variables, but they fail to capture the general idea. Graph theory is famous
for second-order logic applications, with simple ideas like reachability being
difficult to define without second-order quantification. Another example is a
fairly important concept in optimization: the convexity of functions.</p>

\[\forall f, x, y, \alpha: Convex(f) \iff f(\alpha x + (1 - \alpha) y) \leq \alpha f(x) + (1 - \alpha) f(y)\]

<p>with \(\alpha \in \mathbb{R} \mid 0 \leq \alpha \leq 1\), see <a
href='http://www.springer.com/gp/book/9780387303031'>Nocedal &amp; Wright
(2006)</a>. What makes this second order is the quantification over \(f\), a
function. We don't want to define convexity for a specific function, we want to
define it for all functions, hence the need for quantification over
functions.</p>

<h2>What about zeroth-order?</h2>

<p>There is no agreement on what is zeroth-order logic. It is often used to
refer to propositional logic, arguably the most primitive logic, where instead
of predicates we only have propositional symbols, e.g. \(x \land y \implies z\)
is a propositional formula with symbols \(x, y, z\). Since there are no
predicates, and thus no variables, constants, or functions, this is not really
useful to represent maths (although richer logics are often reduced to
propositional logic for inference). The other interpretation is that
zeroth-order logic is first-order logic without variables:</p>

\[CapitalOf(France) = Paris.\]
\[2^{2^2 + 2} = 64.\]
\[\neg Insect(Centipede).\]

<p>With this interpretation, a formula without variables is zeroth-order, one
with only individual variables is first-order, and one with function or predicate
variables is second-order.</p>

]]></summary>
</entry>
<entry>
    <title>Fuzzy knowledge and fuzzy logic connectives</title>
    <link href="http://phdp.github.io//posts/2017-02-21-fuzzy-connectives.html" />
    <id>http://phdp.github.io//posts/2017-02-21-fuzzy-connectives.html</id>
    <published>2017-02-21T00:00:00Z</published>
    <updated>2017-02-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Fuzzy knowledge and fuzzy logic connectives</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="Fuzzy knowledge and fuzzy logic connectives" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2017.02.21
</p>

<p>Interesting things are going on in the world of many-valued logic <a
href='https://arxiv.org/abs/1603.06318'>as recent approaches to combine
first-order logic rules with deep learning tend to involve fuzzying the logic
predicates</a>. Whereas fuzzy logic is fairly simple to understand intuitively,
it has more connectives, or to be exact, alternative ways to define them.</p>

<p>In this post I'll explain a bit why fuzzy logic is interesting in the
context of knowledge representation. Then, I'll introduce various fuzzy logic
connectives and explain how they're connected. Fuzzy logic connectives are
based on triangular norms (T-norms), and the more formal treatments of the
subject tend to care only about conjunction (for good reason, we'll see why).
Here, my goal is to be very explicit and get derive the formulas to compute the
truth values. The maths are really simple, but hopefully the discussion will
still be interesting.</p>

<h2>From expert systems to scientific knowledge</h2>

<p>Fuzzy logic is a radical departure from normal logic. Everything you've done
in mathematics, computer science, and even probability theory, was bivalent.
True or false, and nothing else. Sure, you can say the probability to pick a
queen from a deck of cards is 1/13, but in the end, you'll either have a queen
or not. Again: true or false. Fuzzy logic breaks the mold, considering truth be
be a gradient from 0 (false) to 1 (true). There are various many-valued ("fuzzy")
logics, but here we'll always consider the truth values to be real numbers in
the [0, 1] closed range. An important thing to remember is that fuzzy logic is
a strict superset of bivalent logic, it's more general, and thus the
connectives should behave exactly like bivalent logic connectives when the
truth values are restricted to 0s and 1s.</p>

<p>There's a long tradition in A.I. of building expert systems, arguably the
most famous being MYCIN, which was used for infections, but what if we wanted a
system flexible enough to include complex scientific theories. Turns out that's
tricky. We've made a lot of progress on this front, with frameworks like <a
href='http://phdp.github.io/posts/2015-07-13-srl-code.html'>Markov logic</a>
allowing first-order logic rules to be associated with a weight, which in turn
allows probabilistic queries. Yet you're still limited to true/false values for
predicates. Take for example this seemingly simple idea: when a population is
small and has plenty of preys (or is an autotroph, in which case it has no
preys), it will experience exponential growth. With \(s\) for a species, \(l\)
for a location, and \(t\) for time, we could express the rule in predicate
logic as:</p>

\[SmallPop(s, l) \land (HasPreys(s, l) \lor Autotroph(s)) \Rightarrow N(s, l, t + 1) = R(s) \times N(s, l, t).\]

<p>Where \(SmallPop\) establishes whether the population is small, \(HasPreys\)
whether it has preys, \(Autotroph\) whether it needs preys, and the right-side
of the implication is the traditional formula for exponential growth in discrete
time (\(R\) is the rate of growth).</p>

<p>Even a probability of being true is just not enough, because we never expect
this rule to be exactly true. If you predict 102 rabbits and get 101, it's
"false". Furthermore, predicates like \(SmallPop\) and \(HasPreys\) are better
represented with nuances. With fuzzy logic, we could give a truth value for
\(SmallPop\) based on the current population size compared to a normal-sized
population, we could also quantify \(HasPreys\) on the population densities of
the preys, and perhaps more importantly, we could have an \(ExponentialGrowth\)
predicate and establish its truth value by comparing the predicted population
size to the real population size. In this framework, predicting 102 rabbits
when there are 101 would yield a truth value of 0.99 instead of 0. Note that
it's still possible to assign weights to fuzzy rules, in fact, it's exactly
what <a href='http://stephenbach.net/files/kimmig-probprog12.pdf'>probabilistic
soft logic</a> is about.</p>

<p>But enough exposition, let's explore how the connectives work.</p>

<h2>Normal logic is fuzzy logic with boring values</h2>

<p>With False = 0 and True = 1, you get the following connectives and truth
tables for standard logic:</p>

<table style='width: 80%; text-align:center;'>
  <tr>
    <th>Connective</th>
    <th>Informal name</th>
    <th>Symbol</th>
    <th>1 x 1</th><th>1 x 0</th><th>0 x 1</th><th>0 x 0</th>
  </tr>
  <tr>
    <td>Conjunction</td>
    <td>and</td>
    <td>\(\land\)</td>
    <td>1</td><td>0</td><td>0</td><td>0</td>
  </tr>
  <tr>
    <td>Disjunction</td>
    <td>or</td>
    <td>\(\lor\)</td>
    <td>1</td><td>1</td><td>1</td><td>0</td>
  </tr>
  <tr>
    <td>Implication</td>
    <td>implies</td>
    <td>\(\Rightarrow\)</td>
    <td>1</td><td>0</td><td>1</td><td>1</td>
  </tr>
  <tr>
    <td>Equivalence</td>
    <td>iff</td>
    <td>\(\leftrightarrow\)</td>
    <td>1</td><td>0</td><td>0</td><td>1</td>
  </tr>
  <tr>
    <td>Exclusive disjunction</td>
    <td>xor</td>
    <td>\(\veebar\)</td>
    <td>0</td><td>1</td><td>1</td><td>0</td>
  </tr>
</table>

<p>Plus, we have one unary connective, negation, represented by \(\neg\). In
practice all the connectives can be defined with only negation and
conjunction:</p>

\[x \land y.\]
\[x \lor y = \neg(\neg x \land \neg y).\]
\[x \Rightarrow y = \neg x \lor y = \neg (x \land \neg y).\]
\[x \leftrightarrow y = (x \Rightarrow y) \land (y \Rightarrow x) = \neg (x \land \neg y) \land \neg (y \land \neg x).\]
\[x \veebar y = \neg (x \leftrightarrow y) = \neg (\neg (x \land \neg y) \land \neg (y \land \neg x)).\]

<p>The definition of disjunction using only negation and conjunction leads us
to the famous De Morgan laws:</p>

\[\neg(x \land y) = \neg x \lor \neg y\]
\[\neg(x \lor y) = \neg x \land \neg y\]

<p>We won't talk about quantifiers (forall \(\forall\) and exists \(\exists\)),
let's just say that, even in this case, for a formula \(x\), the formula
\(\exists x\) could be written \(\neg \forall \neg x\). I say this because,
while we explore all the connectives here, formal texts will often define the
smallest possible set of symbols. The larger set of connectives and qualifiers
are mostly there for us, to make things easier to read and understand. Typical
pandering to humans :P. As a quick side note, there's intriguing work being
done on <a
href='http://link.springer.com/chapter/10.1007/978-3-319-40566-7_5'>soft
qualifiers</a> for fuzzy logic. But back to the connectives...</p>

<h2>A first bite of fuzzy connectives</h2>

<p>With False = 0 and True = 1, and given that we expect the fuzzy connectives
to behave the same as bivalent connectives, we can have:</p>

\[\neg x = 1 - x.\]
\[x \land y = min(x, y).\]
\[x \lor y = max(x, y).\]

<p>So \(\neg 1 = 0\), \(1 \land 0 = 0\), \(0 \land 1 = 1\), you can check,
these connectives behave like normal bivalent connectives when they need to
but they're also defined for other values: with \(x = 0.1\) and \(y = 0.7\)
we get \(x \land y = 0.1\) and \(x \lor y = 0.7\). Let's try to see if
our definition of disjunction using only conjunction and negation works
too:</p>

\[x \lor y = \neg(\neg x \land \neg y).\]
\[x \lor y = \neg min(\neg x, \neg y).\]
\[x \lor y = 1 - min(1 - x, 1 - y).\]

<p>Turns out, \(max(x, y)\) is indeed the same as \(1 - min(1 - x, 1 - y)\).
To see why it's helpful to use a more geometric formula for the minimum and
maximum:</p>

\[max(a, b) = \frac{a + b + |a - b|}{2}.\]
\[min(a, b) = \frac{a + b - |a - b|}{2}.\]

<p>The intuition behind the formulas above is that the maximum is the mid-point
\((a + b)/2\) <emph>plus</emph> half the distance between \(a\) and \(b\) (i.e.:
\(|a - b|\)), while the minimum is the mid-point <emph>minus</emph> half the
distance. Back to our definition of disjunction:</p>

\[max(x, y) = 1 - min(1 - x, 1 - y),\]
\[max(x, y) = 1 - 0.5(1 - x + 1 - y - |1 - x - 1 + y|),\]
\[max(x, y) = 0.5(x + y + |y - x|).\]

<p>...and that's our definition of maximum (remember that \(|a| = |-a|\).</p>

<p>Alright! We have our simple, happy definitions for conjunction and
disjunction with continuous values. These definition are awesome: they are both
simpler and more general than the truth tables we normally get for logic
connectives... but there's a catch: there are other ways to define the fuzzy
connectives. For example</p>

\[x \land y = max(0, x + y - 1).\]
\[x \lor y = min(1, x + y).\]

<p>Our first definitions for fuzzy connectives were based on the Gödel T-norm,
while these are based on the Lukasiewicz T-norm. Again, is our definition of
disjunction from conjunction valid?</p>

\[x \lor y = \neg(\neg x \land \neg y),\]
\[min(1, x + y) = \neg max(0, \neg x + \neg y - 1),\]
\[min(1, x + y) = 1 - max(0, 1 - x + 1 - y - 1),\]
\[min(1, x + y) = 1 - max(0, 1 - x - y),\]
\[0.5(1 + x + y - |1 - x - y|) = 1 - 0.5(0 + (1 - x - y) + |0 - (1 - x - y)|),\]
\[0.5(1 + x + y - |1 - x - y|) = 1 - 0.5(1 - x - y + |x + y - 1|),\]
\[0.5(1 + x + y - |1 - x - y|) = 0.5(1 + x + y - |x + y - 1|),\]

<p>Works fine! These definitions might look needlessly complicated compared to
the simple \(min(x, y)\) for conjunction, but they often make more sense since
they combine the truth values instead of just discarding one like the
minimum.</p>

<p>Defining implication in Lukasiewicz logic is straightforward:</p>

\[x \Rightarrow y = \neg x \lor y,\]
\[x \Rightarrow y = min(1, 1 - x + y).\]

<p>As for equivalence:</p>

\[x \leftrightarrow y = (x \Rightarrow y) \land (y \Rightarrow x),\]
\[x \leftrightarrow y = min(1, 1 - x + y) \land min(1, 1 - y + x),\]
\[x \leftrightarrow y = max(0, min(1, 1 - x + y) + min(1, 1 - y + x) - 1),\]
\[x \leftrightarrow y = max(0, 0.5(4 - x + y - y + x - | x - y| - |y - x|) - 1),\]
\[x \leftrightarrow y = max(0, 1 - |x - y|).\]

<p>Technically, this is the definition of equivalence, but in practice since
\(x - y\) can never be greater than 1 with the truth values restricted to the
[0, 1] range, we can simplify to</p>

\[x \leftrightarrow y = 1 - |x - y|.\]

<p>And we'll define exclusive disjunction from there:</p>

\[x \veebar y = \neg (x \leftrightarrow y),\]
\[x \veebar y = 1 - (1 - |x - y|),\]
\[x \veebar y = |x - y|.\]

<p>We have all our connectives, plus two versions of disjunction and
conjunction. We'll now explore T-norm. Yes, there are more possible
connectives.</p>

<h2>Triangular norm (T-norm)</h2>

<p>So we have two ways to define conjunction, are there others? Yes! A
T-norm is a function from \([0, 1]^2 \rightarrow [0, 1]\) that satisfies the
following properties given \(x, y, z, z', y' \in [0, 1]\):</p>

<ol type="I">
  <li>\(t(x, 0) = 0\).</li>
  <li>\(t(x, 1) = x\).</li>
  <li>Commutativity: \(t(x, y) = t(y, x)\).</li>
  <li>Associativity: \(t(x, t(y, z)) = t(t(x, y), z)\).</li>
  <li>Monotonicity: If \(x \leq x', y \leq y'\), then \(t(x, y) \leq t(x', y')\).</li>
</ol>

<p>We also have the T-conorm, which has the same properties as the T-norm
except the the first two properties are changed to \(t(x, 0) = x\) and \(t(x,
1) = 1\).</p>

<p>So what is a T-norm? Multiplication, yes, simple plain multiplication, is a
valid T-norm:</p>

\[x \land y = x \times y.\]
\[x \lor y = 1 - ((1 - x) \times (1 - y)).\]
\[x \lor y = y + x - xy.\]

<p>At this point we have three ways to define conjunction: \(min(x, y)\), which
is called Gödel's T-norm (or Gödel-Dummett), \(max(0, x + y - 1)\) which is
Lukasiewicz' T-norm, and finally we have simple multiplication, often
called the product T-norm.</p>

<h2>Appendix: Connectives all in one place for Łukasiewicz logic</h2>

<table style='width: 80%'>
  <tr><th>Connective</th>             <th>Equation</th></tr>
  <tr><td>Conjunction</td>            <td>\(max(0, x + y - 1)\)</td></tr>
  <tr><td>Weak Conjunction</td>       <td>\(min(x, y)\)</td></tr>
  <tr><td>Disjunction</td>            <td>\(min(1, x + y)\)</td></tr>
  <tr><td>Weak Disjunction</td>       <td>\(max(x, y)\)</td></tr>
  <tr><td>Implication</td>            <td>\(min(1, 1 - x + y)\)</td></tr>
  <tr><td>Equivalence</td>            <td>\(1 - |x - y|\)</td></tr>
  <tr><td>Exclusive disjunction</td>  <td>\(|x - y|\)</td></tr>
</table>

]]></summary>
</entry>
<entry>
    <title>CMake project templates for C++11 and CUDA with google test/benchmark support</title>
    <link href="http://phdp.github.io//posts/2017-01-30-cmake.html" />
    <id>http://phdp.github.io//posts/2017-01-30-cmake.html</id>
    <published>2017-01-30T00:00:00Z</published>
    <updated>2017-01-30T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>CMake project templates for C++11 and CUDA with google test/benchmark support</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="CMake project templates for C++11 and CUDA with google test/benchmark support" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2017.01.30
</p>

<p>Books generally don't cover project organization and few introductions to
C++ discuss testing frameworks, let alone benchmarking. In my experience, many
science students compile without optimization flags, don't know how to separate
header and source files, tests, etc etc. So I created two simple <a
href='https://cmake.org/'>cmake</a> project templates. One for C++11 (with a
library and an executable) and one for CUDA. Both support testing with <a
href='https://github.com/google/googletest'>Google Test</a> and benchmarks with
<a href='https://github.com/google/benchmark'>Google Benchmark</a>.</p>

<ul>
  <li><a href='https://github.com/PhDP/cmake-gtest-gbench-starter'>C++11 cmake project with google test / google benchmark support.</a></li>
  <li><a href='https://github.com/PhDP/cuda-cmake-gtest-gbench-starter'>C++/CUDA cmake project with google test / google benchmark support.</a></li>
</ul>

<p><a href='https://cmake.org/'>CMake</a> is a popular tool for building
cross-platform C++ applications, you shouldn't have any issue installing
it.</p>

<p>The C++ project template works on both Linux/UNIX and Windows, while the
CUDA project is tested only on Linux. Feel free to fork / suggest
improvements.</p>

]]></summary>
</entry>
<entry>
    <title>Ten years on Linux</title>
    <link href="http://phdp.github.io//posts/2017-01-27-linux.html" />
    <id>http://phdp.github.io//posts/2017-01-27-linux.html</id>
    <published>2017-01-27T00:00:00Z</published>
    <updated>2017-01-27T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Ten years on Linux</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="Ten years on Linux" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2017.01.27
</p>

<p>I moved from Windows to <a href='https://www.linuxfoundation.org/'>Linux</a>
at the end of 2007, roughly ten years ago. I did many of the crazy things new
users do, from <a href='https://www.gentoo.org/'>Gentoo</a> to <a
href='https://www.archlinux.org/'>Arch</a>, but mostly used <a
href='https://getfedora.org/'>Fedora</a> and <a
href='https://www.ubuntu.com/'>Ubuntu</a>.</p>

<p>I thought ten years was worth writing about... but honestly, the big thing
to write about may be that there's little to write about. I installed Linux on
roughly a dozen machines in 2016 (my machines, plus some owned by friends and
family). The only issue I remember is having to install Ubuntu server on my
desktop computer because the graphical installer couldn't work with the GTX
1080. I installed the server version, then NVIDIA's drivers, then the graphical
interface, et voilà... A few days ago I completely removed Windows from an MSI
laptop (yeppie, GTX 1070 GPU!). It just works.</p>

<p>Linux is boring in a very nice, productivity-friendly way. Almost everything
I need, from Cuda 8 to compilers and librairies, can be installed with a simple
'sudo apt install'. It's probably not for everyone, but for machine learning
research I cannot imagine a better platform.</p>

<p style='text-align: center;'><img src='../images/2017_setup.png' alt='Setup 2017'/></p>

]]></summary>
</entry>
<entry>
    <title>Can AlphaGo beat Imperial?</title>
    <link href="http://phdp.github.io//posts/2016-07-05-can-alphago.html" />
    <id>http://phdp.github.io//posts/2016-07-05-can-alphago.html</id>
    <published>2016-07-05T00:00:00Z</published>
    <updated>2016-07-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Can AlphaGo beat Imperial?</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="Can AlphaGo beat Imperial?" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2016.07.05
</p>

<p><a
href='http://www.theverge.com/2016/3/10/11192774/demis-hassabis-interview-alphago-google-deepmind-ai'>DeepMind's
Demis Hassabis recently singled out StarCraft as a potential challenge for
AlphaGo.</a> It's a fascinating, and bold, target. StarCraft is a partial
information game with many different short- and long-term trade offs, and
because you have so many units, ways to position them, research options,
buildings, resources, StarCraft's game tree size dwarfs Go's. Compared to
chess, Go is complex, but in the grand scheme of things, a game involves
roughly 75 decisions with less than 361 legal moves. I'm not saying this to
diminish AlphaGo's achievement. On the contrary, I never thought an AI would
dominate a match against a top player this soon. It seems like yesterday that
Go AIs were, at best, playing at the level of good amateurs.</p>

<p>Still, how far can AlphaGo go? Or perhaps more generally, how far can <a
href='https://www.nervanasys.com/demystifying-deep-reinforcement-learning/'>
deep reinforcement learning</a> go? I'd love to see hard numbers, but the game
tree size of the {Starcraft, Fire Emblem, Civilization} of this world must be
humongous. Players have to make several decisions every seconds, if not several
decisions per second. Yet, personally, I'm equally interested in seeing how far
deep learning-based reinforcement learning can go for board games. <a
href='https://arxiv.org/abs/1509.01549'>Chess</a> is certainly on the table,
but what about other board games? Take one of my favorites: <a
href='https://boardgamegeek.com/boardgame/24181/imperial'>Imperial</a>.</p>

<p>So what the hell is Imperial? Like chess and Go, Imperial is a deterministic
perfect-information game. While Go is complex, it is relatively "flat" in the
sense that the game is a grid with one object (the stone). In contrast,
Imperial has many different objects. Military units and factories make the game
look like a standard variation of Risk, but the game has a twist: players are
not assigned to a country at the beginning of the game. Countries make their
moves in turn, but who control the country at any given time is determined by
who invested the most in it. This simple rule creates complex strategies where
players will take control of countries in poor shape to help their investments
elsewhere.</a>

<p>I doubt Google cares about an obscure (yet awesome) board game like
Imperial, but maybe they should, because (I think) it highlights a bit of a
blind spot for deep reinforcement learning. The main issue with Imperial is not
that the game is very complex (it isn't), or that a particular rule would trip
the AI. The issue is simply that we have no large databases of games to feed to
an algorithm. Data deluge or not, it's typical to have little data when faced
with a new problem, and it's not the end of the world for all machine learning
approaches. We can encode a rough model ourselves, something fairly common with
probabilistic graphical and statistical relational models, or by transferring
knowledge from a similar problem.</p>

<p>Putting together a reinforcement learning agent based on my (upcoming)
open-source C++ library for statistical relational learning is very high on my
priority list, we'll see if it can beat Imperial. That said, I'd also like to
see deep reinforcement learning tackle this kind of problem. After all, transfer
learning is high on the radar of <a
href='http://www.iro.umontreal.ca/~bengioy/talks/DL-Tutorial-NIPS2015.pdf'>deep
learning researchers</a>, and we can't really talk of general intelligence as
long as the A.I. needs to learn everything from 0.</p>

]]></summary>
</entry>
<entry>
    <title>Data Scientists: This is not your grandmother's C++</title>
    <link href="http://phdp.github.io//posts/2016-06-28-not-your-grandmother-cpp.html" />
    <id>http://phdp.github.io//posts/2016-06-28-not-your-grandmother-cpp.html</id>
    <published>2016-06-28T00:00:00Z</published>
    <updated>2016-06-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Data Scientists: This is not your grandmother's C++</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="Data Scientists: This is not your grandmother's C++" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2016.06.28
</p>

<p>A quick note. I saw a few lines of antiquated C++ in a Python presentation
for the obligatory "look-how-C++-sucks" bit. If you like Python, good for you,
I'm not here to bash it. But for the love of Hopper, stop freaking people out
with old, outdated C++. Many (most?) high-performance machine learning
libraries are written in modern C++, often with a Python interface. If you want
to understand how hot new tools like <a
href='https://github.com/tensorflow/tensorflow'>TensorFlow</a> or <a
href='https://github.com/Microsoft/CNTK'>CNTK</a> work: you'll learn a lot by
diving into their C++ core.</p>

<p>The scary C++ examples follow a common theme: show how something simple is
absurdly contrived in C++ compared to Python. Hey let's create a vector (well,
it'll be a list in Python) of sets and print the result in some format:</p>

<pre><code class="python">sets = [{1, 2, 3}, {4, 5, 6}, {42, 47, 15}]

for set in sets:
  print('{ ', end='')
  for i in set:
    print(str(i) + ' ', end='')
  print('}')</code></pre>

<p>Clean and simple. Now the C++ version, Frankenstein's monster in code
form, look how ugly it is:</p>

<pre><code class="cpp">#include &lt;iostream&gt;
#include &lt;set&gt;
#include &lt;vector&gt;

int main() {
  using namespace std;

  vector&lt;set&lt;int&gt; &gt; sets;

  {
    set&lt;int&gt; tmp;
    tmp.insert(1);
    tmp.insert(2);
    tmp.insert(3);
    sets.push_back(tmp);

    tmp.clear();
    tmp.insert(4);
    tmp.insert(5);
    tmp.insert(6);
    sets.push_back(tmp);

    tmp.clear();
    tmp.insert(42);
    tmp.insert(47);
    tmp.insert(15);
    sets.push_back(tmp);
  }

  vector&lt;set&lt;int&gt; &gt;::const_iterator it = sets.begin();
  for (; it != sets.end(); ++it) {
    cout &lt;&lt; "{ ";
    for (set&lt;int&gt;::const_iterator j = it-&gt;begin(); j != it-&gt;end(); ++j)
      cout &lt;&lt; *j &lt;&lt; ' ';
    cout &lt;&lt; "}\n";
  }

  return 0;
}</code></pre>

<p>Kill it! Kill it with fire! Everything from creating the vector of sets to
looping is awful... Except that's C++98. Nobody in their right mind is using
C++98 unless they're forced to. I'm not even sure this is good C++98 code, I
haven't written with this standard in ages. It's easy to forget not so long ago
we couldn't write vector&lt;set&lt;int&gt; &gt; without adding a space between
the two &gt;&gt;.  In modern C++, the code looks like this:</p>

<pre><code class="cpp">#include &lt;iostream&gt;
#include &lt;set&gt;
#include &lt;vector&gt;

auto main() -&gt; int {
  using namespace std;

  auto const sets = vector&lt;set&lt;int&gt;&gt;{{1, 2, 3}, {4, 5, 6}, {42, 47, 15}};

  for (auto const& set : sets) {
    cout &lt;&lt; "{ ";
    for (int i : set)
      cout &lt;&lt; i &lt;&lt; ' ';
    cout &lt;&lt; "}\n";
  }

  return 0;
}</code></pre>

<p>That's C++11 in action. I prefer this code to the Python version: it
type-checks, compiles to efficient code, and gives you better control over
memory (using references vs copy). You may prefer the Python version, fine, but
it's not <i>that</i> different. Plus, as Python and C++ follow similar
paradigms (except for type checking), the things that tend to be annoying to
write in C++, <a href='2015-04-05-automated-reasoning.html'>e.g.  handling
abstract syntax trees</a>, are equally painful in Python. So stop what you're
doing, <a href='http://www.informit.com/store/discovering-modern-c-plus-plus-an-intensive-course-9780134383699'>grab
a good book</a>, and learn modern C++.</p>

]]></summary>
</entry>
<entry>
    <title>Scientific theories &amp; machine learning</title>
    <link href="http://phdp.github.io//posts/2015-11-02-theory-and-ml.html" />
    <id>http://phdp.github.io//posts/2015-11-02-theory-and-ml.html</id>
    <published>2015-11-02T00:00:00Z</published>
    <updated>2015-11-02T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Scientific theories &amp; machine learning</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="Scientific theories &amp; machine learning" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2015.11.02
</p>

<p>Peter Norvig, director of research at Google,
  <a href='http://norvig.com/chomsky.html'>wrote a few interesting articles on machine learning in natural language processing.</a>
  In <a href='http://norvig.com/fact-check.html'>this one</a>, he makes the case for
using machine learning instead of handmade theories in complex domains:</p>

<blockquote> <p>But to be clear: the methodology still involves models. Theory
  has not ended, it is expanding into new forms. Sure, we all love succinct
  theories like \(F = ma\). But social science domains and even biology appear
  to be inherently more complex than physics. Let's stop expecting to find a
  simple theory, and instead embrace complexity, and use as much data as well
  as we can to help define (or estimate) the complex models we need for these
  complex domains.</p> </blockquote>

<p>In the same vein, just a tad more radical, Chris Anderson wrote
<a href='http://archive.wired.com/science/discoveries/magazine/16-07/pb_theory'>
  The End of Theory: The Data Deluge Makes the Scientific Method Obsolete</a>.</p>
  
<p>Machine learning is a puzzle for scientists. Ever since, well, the early
days of science, we've relied primarily of predictions to select the best
theories.  Quantum physics didn't become popular because of its fancy name, and
certainly not because it was intuitive. It gained momentum because it worked,
it was able to make correct predictions where other theories faltered. Machine
learning is different, it is a set of algorithms designed to build models.
Theories to build theories automatically from data. The fundamental difference
between quantum physics and the theories generated with statistical machine
learning is that you can peek inside the model of the former to get a clear
understanding of what makes quantum systems tick, while the latter is often an
opaque black box. There are also important differences in how theories are
evaluated and selected (side-note: I'll use <i>theory</i> and </i>model</i>
interchangeably).</p>

<p>There aren't enough discussions about machine learning and how it relates to
the traditional role of theoretical scientists. Machine learning has been
surprisingly effective at cracking complex problems in a wide array of domains.
It's almost impossible to use a smartphone or browse the internet for a few
minutes without being fed the output of several machine learning algorithms.
Meanwhile, fields like theoretical population genetics, theoretical ecology,
natural language processing, and many others, struggle with complexity. I
enthusiastically support Norvig's call to embrace complexity, but at the same
time we lose something fundamental to science by relying on statistical machine
learning approaches. So what <i>is</i> the place of machine learning? I doubt
there is a simple answer to the question, but machine learning represents an
important paradigm shift, we've never relied so much on models that were not
directly built by humans. We won't be able to avoid serious discussions about
how machine learning relates to the traditional role of theory in science.</p>

<p>So let's talk a bit about machine learning and scientific theories.</p>

<h2>The queen of science</h2>

<p>Traditional theory-making is symbolic. We find equations with symbols
representing objects and functions establishing relations between objects. No
need to look very far, Norvig quotes Newton's second law of motion \(F = ma\),
which establishes that force equals mass times acceleration.</p>

<p>The beauty of such theories is that they are, implicitly, all part of that
big corpus of knowledge we call science. If you have an equation somewhere with
acceleration, you can replace it with \(F/m\), and the fact that you can
transform \(F = ma\) into \(a = F/m\) is itself part of our understanding of
mathematics. It seems silly and obvious, but it's really the strength of these
theories: they are all part of a single interconnected base of knowledge about
the universe. Henri Poincaré wrote:</p>

<blockquote>
<p>The Scientist must set in order. Science is built up of facts, as a house is
with stones. But a collection of facts is no more a science than a heap of
stones is a house.</p>
</blockquote>

<p>Theory is the house, it's what allows us to structure knowledge. A
statistical model found by a machine learning algorithm, even a probabilistic
graphical model, doesn't do much to build the house. As effective as it may be
to solve a specific problem, it fails as an integrative force. The issue
is probably best explained by a table from <a
href='http://aima.cs.berkeley.edu/'>Russell &amp; Norvig</a> (<i>him</i>
again!?!):</p>

<table style='width:100%'>
  <tr>
    <th><b>Language</b></th>
    <th><b>Ontological commitment</b></th>
    <th><b>Epistemological commitment</b></th>
  </tr>
  <tr>
    <td>Probability Theory</td>
    <td>Facts</td>
    <td>Degree of belief \(\in [0, 1]\)</td>
  </tr>
  <tr>
    <td>Logic (First-Order)</td>
    <td>Facts, objects, relations.</td>
    <td>True | False | Unknown</td>
  </tr>
<!--
  <tr>
    <td>Statistical relational learning</td>
    <td>Facts, objects, relations</td>
    <td>Degree of belief \(\in [0, 1]\)</td>
  </tr>
-->
</table>

<p>The key point is that statistical models are inherently limited in their
ability to build knowledge bases, since their framework (probability theory)
only recognizes facts, but no objects or relations between objects.</p>

<p>If we want to be fair in our comparison of machine learning and traditional
theory-making, we must take into account the ability of symbolic theories to
connect with each others. A statistical model that fits a dataset well and
generate good predictions is definitely useful, but it does not contribute to
knowledge in the same way as a symbolic model.</p>

<h2>The great obsession</h2>

<p>Well then, traditional theory-making is <i><b>good</b></i>, and hipster
machine learning is <i><b>bad</b></i>, right? Not so fast. The enthusiasm for
machine learning comes from the fact that many problems involve complex
relationships between many variables and, before machine learning, this large
class of problems remained mostly out of our reach. It's hard, perhaps
impossible, to discover these theories by hand. Evolutionary theory offers a
great example.</p>

<p>Things got serious for evolutionary biology in the 1910s-1920s as Wright,
Fisher, and Haldane founded the field of theoretical population genetics. In a
short period of time, Darwin's natural selection was clearly defined in terms
of Mendelian genetics, and other mechanisms like random genetic drift were
described.  Fundamental equations were written, new maths were developed along
the way, and all seemed well. A few decades later, with the rise of molecular
biology, we started to have a clearer view of biodiversity in the wild.
Unsurprisingly, we were (again) surprised by how diverse and complex
biodiversity was.  The world was much more diverse than anticipated. Much more
than our theories predicted. Theoretical scientists got back to work to find a theory
that would explain how so much diversity could be maintained.</p>

<p>Gillespie, a prominent theoretician, called this the <i>Great Obsession</i>.
We know the basic mechanisms underlying evolution, but we just can't find an
equation to relate them in an effective predictive model. We even have a pretty
good idea why it's so difficult: selection fluctuates in time and space,
linkage and positive selection combines to draft neutral and even deleterious
mutations, and the effect of mutations vary (a lot) across the genome.
Knowing all this didn't help us find a solid theory. In 2008, Matthew Hahn
wrote
<a href='http://onlinelibrary.wiley.com/doi/10.1111/j.1558-5646.2007.00308.x/abstract'>
 a damning paper</a>
that illustrates just how far we are from resolving the problem of
biodiversity. His major qualm is that, since we have no solid predictive model
for diversity, we tend to rely on neutral models (...and they just don't work).
In his words:</p>

<blockquote><p>The consequence of this is that we have tied ourselves into
philosophical knots by using null models no one believes but are easily
parameterized.</p></blockquote>

<p>It's a trap! A model is widely believed to be wrong, generate poor
predictions, but is so easy to parametrize that we use it. To be clear: we are
not trading a bit of accuracy for easy parametrization, we are adopting models
that are plain wrong (Hahn's paper is highly recommended for anyone interested
in evolution or biodiversity). That's not how science is supposed to work. And
it's just one example of how theory is difficult for humans to build when several
variables are involved. An unfortunate side-effect is to demote theory, to use
it to build toy-models supposedly used to bring "insights", but how can we expect
good insights from theories that were not validated in the first place? Again,
it's not how science (and theory) works, and this "theory-as-insights" philosophy
risks confirming our biases as we inevitably build theories with biases and
do not look for the theory's effectiveness. In the excellent
  <a href='http://www.nssl.noaa.gov/users/brooks/public_html/feda/papers/Oreskes1.pdf'><i>Verification, validation, and confirmation of numerical models in the Earth sciences</i></a>,
Naomi Oreskes and her colleagues ends by saying:</p>

<blockquote><p>[W]e must admit that a model may confirm our biases and support
incorrect intuitions.</p></blockquote>

<p>On the other hand, machine learning algorithms have built effective model
for voice recognition, image classification, several problems in natural
language processing, ecology, molecular biology... They have proven over and
over again their ability to build models when hundreds or thousands of
variables are involved. Theoretical scientists can't do that.</p>

<h2>A false dilemma</h2>

<p>So where does it lead us? In complex domains, statistical machine learning
give us good predictive models, but it's difficult, if not impossible, to
understand what is going on inside the model. And more importantly, the
theories generated don't connect with other theories like symbolic models.
Picasso famously said that <i>computers are useless, they only give
answers.</i> I guess a theoretician could quip that machine learning algorithms
are useless, they only give specialized prediction machines. For a long time,
being able to predict was our way to know we understood a system. General
relativity replaced the classical theory of gravity because it made better
predictions, and we could peek inside the equations to gain an understanding of
how different objects interact to generate gravity. Theoretical understanding
and predictive power intertwined, but only in domains simple enough to expect a
human to figure out the inner working of the system.</p>

<p>In many cases, statistical machine learning is good enough. Throw data at an
algorithm, get an effective predictive model, and you're done (well, it's a bit
trickier in practice, but you get the idea). We don't necessarily need
theoretical understanding of how an array of pixels of different colors
represent a cat. Dogs are more awesome anyway. The issue is that, as
scientists, we often <b>do</b> need more than effective models built for a
specific dataset. Unification, synthesis, integration, whatever you want to
call it, being able to connect apparently distinct phenomenons into a single
theory is a key goal of science.</p>

<p>The good news is that there is a way to unify traditional theory-making with
machine learning. This isn't some speculation about how the field of A.I.  /
machine learning could evolve, this
  <a href='http://www.aclweb.org/anthology/P09-1046.pdf'>is</a>
  <a href='http://www.biomedcentral.com/1471-2105/14/273'>already</a>
  <a href='http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3122930/'>being</a>
  <a href='http://bioinformatics.oxfordjournals.org/content/27/18/2586.full.pdf'>done</a>
  <a href='http://ciir-publications.cs.umass.edu/getpdf.php?id=928'>successfully.</a>
I'm currently working on a project with
  <a href='http://www.cs.man.ac.uk/~filannim/'>Michele Filannino</a>
  where the initial model was built by experts who figured out the right set of
formulas, connecting many NLP tasks together into a relatively small, and
highly effective, model. Our plan involves using machine learning to learn
weights for these formulas and then using another machine learning approach to
look for new formulas or more effective variants of the existing model. The
model is not a black box, it's a set of formulas. It's definitely possible to
use machine learning to learn symbolic models, to improve our hand-made elegant
theories, and to contribute to the synthesis of a domain. I would argue that,
in complex domains where traditional theory-making struggles to find effective
theories, this hybrid symbolic / probabilistic approach is probably necessary.
<a href='http://homes.cs.washington.edu/~pedrod/papers/mlj05.pdf'>
  Markov logic</a>,
<a href='http://homes.cs.washington.edu/~pedrod/papers/aaai15.pdf'>
  relational sum type networks</a>,
and many other approaches to machine learning allow us to interact with the
model in ways that are impossible with purely statistical machine learning
algorithms. It's not necessarily a better approach in general, but it seems to
align better with the role of theory in science.</p>


]]></summary>
</entry>
<entry>
    <title>A gentle introduction to statistical relational learning: maths, code, and examples</title>
    <link href="http://phdp.github.io//posts/2015-07-13-srl-code.html" />
    <id>http://phdp.github.io//posts/2015-07-13-srl-code.html</id>
    <published>2015-07-13T00:00:00Z</published>
    <updated>2015-07-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>A gentle introduction to statistical relational learning: maths, code, and examples</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="A gentle introduction to statistical relational learning: maths, code, and examples" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2015.07.13
</p>

<p>Statistical relational learning is a branch of machine learning (A.I.)
devoted to unify probability theory and logic. I'll write another post later
to explain the motivation and a bit of history of this fascinating branch of
study, but here I want to focus on a concrete example, with detailed
maths and code.</p>

<p>The approach to statistical relational learning explained here is called
Markov logic network (MLN), <a
href='https://homes.cs.washington.edu/~pedrod/kbmn.pdf'>discovered in 2006 by
Richardson and Domingos.</a> Their paper has a nice simple example of MLN
applied to the relationship between smoking and cancer. However, it's a bit
hard to follow unless you're used to read papers on both logic and
probabilistic graphical models.  In this post, I will mostly follow their
smoking/cancer example, but I will try to be much more explicit. I'll also do a
demonstration with <a href='https://github.com/PhDP/Faun'>Faun</a>, a
small implementation I wrote for playing with statistical relational models.</p>

<p>A Markov logic network is simply a set of formulas written in first-order
logic, each associated with a weight. We'll use this for our examples:</p>

<table style='width: 80%'>
  <tr>
    <th>Statement</th>
    <th>Weight</th>
  </tr>
  <tr>
    <td>Smoking causes cancers</td>
    <td align='center'>1.5</td>
  </tr>
  <tr>
    <td>If two people are friends and one smokes, then so does the other</td>
    <td align='center'>1.1</td>
  </tr>
</table>

<p>Using a more formal representation, with the weight following the
first-order logic formula, we get:</p>

\[\forall x: Smoking(x) \Rightarrow Cancer(x), 1.5;\]
\[\forall x, y: Friend(x, y) \land Smoking(x) \Rightarrow Smoking(y), 1.1;\]

<p>And that's our Markov logic network. If you don't know much about
first-order logic, <a href='2015-07-13-fol.html'>I wrote a short introduction
here that is more than enough to understand Markov logic networks</a>.</p>

<p>The grand idea of statistical relational learning is that, in pure logic, a
world is false if it violates a single formula, but with Markov logic networks,
a world is <i>less likely</i> if it violates formulas, especially if it
violates a formula with a high weight. Statistical relational learning has
important advantages on probabilistic approaches: a first-order logic formula
is simple to understand and interpret, plus it can be manipulated by humans and
computers in ways a naked probabilistic model can't. I think the greatest
advantage of Markov logic networks, and statistical relational approaches in
general, is to go beyond data models to form a general knowledge base. Just
like old expert systems, but without the inflexibility of logic.</p>

<p>But enough with the background, let's look at an example.</p>

<h2>From Markov logic networks to inference in Markov networks</h2>

<p>The first odd thing with Markov logic networks, is that there's no network
(yet). All we got is a set of weighted first-order logic formulas. A Markov
logic network can be seen as a template for Markov networks. That is: there is
no network in the Markov logic network, but we'll use it to generate networks.
Take the formula:</p>

\[\forall x: Smoking(x) \Rightarrow Cancer(x), 1.5;\]

<p><i>x</i> is a variable, and to get a concrete model for inference from this
template, we need to apply constants (real objects) to the MLN so we can
replace these variables. So in essence:</p>

\[\mbox{MLN (weighted formulas) + Constants} \rightarrow \mbox{Markov Network}\]

<p>If you're confused, don't worry, it'll become clear with examples. Let's say
we are interested in the relationship between smoking/cancer/friendship for
three constants: Jerry, Elaine, George. We can apply these constants to the
formula to get a set of ground formulas.  The term <i>ground</i> means the
variables are replaced by constants, that is, concrete objects. For example in
mathematics you probably encountered first-order logic formulas like:</p>

\[\forall x: Add(x, 0) = x.\]

<p>We can ground this first-order logic formula by replacing <i>x</i> with an
actual integer:</p>

\[Add(47, 0) = 47.\]
\[Add(1729, 0) = 1729.\]

<p>Similarly, applying the set of constants \(\{Elaine, Jerry, George\}\) to
our first formula yields a set of ground formulas:</p>

\[Smoking(Elaine) \Rightarrow Cancer(Elaine), 1.5;\]
\[Smoking(Jerry) \Rightarrow Cancer(Jerry), 1.5;\]
\[Smoking(George) \Rightarrow Cancer(George), 1.5;\]

<p>We could do the same thing with the other formula, which has two variables:</p>

\[Friend(Elaine, Elaine) \land Smoking(Elaine) \Rightarrow Smoking(Elaine), 1.1;\]
\[Friend(Elaine, Jerry) \land Smoking(Elaine) \Rightarrow Smoking(Jerry), 1.1;\]
\[Friend(Elaine, George) \land Smoking(Elaine) \Rightarrow Smoking(George), 1.1;\]
\[Friend(Jerry, Elaine) \land Smoking(Jerry) \Rightarrow Smoking(Elaine), 1.1;\]
\[Friend(Jerry, Jerry) \land Smoking(Jerry) \Rightarrow Smoking(Jerry), 1.1;\]
\[Friend(Jerry, George) \land Smoking(Jerry) \Rightarrow Smoking(George), 1.1;\]
\[Friend(George, Elaine) \land Smoking(George) \Rightarrow Smoking(Elaine), 1.1;\]
\[Friend(George, Jerry) \land Smoking(George) \Rightarrow Smoking(Jerry), 1.1;\]
\[Friend(George, George) \land Smoking(George) \Rightarrow Smoking(George), 1.1;\]

<p>We'll get our network from these ground formulas. From the groundings of the
two formulas, we get a set of predicates:</p>

\[\{Smoking(Elaine), Smoking(Jerry), Smoking(George), Cancer(Elaine),\]

\[Cancer(Jerry), Cancer(George), Friend(Elaine, Elaine), Friend(Elaine, Jerry),\]

\[Friend(Elaine, George), Friend(Jerry, Elaine), Friend(Jerry, Jerry),\]

\[Friend(Jerry, George), Friend(George, Elaine),\]

\[Friend(George, Jerry), Friend(Jerry, George)\}\]

<p>Markov logic networks provide the structure to answer question of the type</p>

\[P(Cancer(George) \mid Smoking(Jerry), Friend(Jerry, George)),\]

<p>where our variables (in the probabilistic sense) are the ground predicates.
Of course, we could generate a completely different set of ground formulas and
ground predicates if we apply, say, the constants \(\{William, Anastasia,
Kara, Saul, Karl, Tory, Felix, Laura\}\), or any number of objects we're
interested in.</p>

<p>To finally see the network and answer probabilistic queries, we'll create
one node for each ground predicate, and link all nodes that are in the same
ground formula. In our example with the constants \(\{Elaine, Jerry, George\}\), we
get the following Markov network:</p>

<div class="imagecenter">
  <img src="../images/ground_seinfeld.png" alt="ground network"/>
</div>

<p>That said, to make it easier to follow, we'll generate a simpler network by
applying only two constants to the same two formulas: \(\{Kara, Lee\}\). We
get:</p>

<div class="imagecenter">
  <img src="../images/mln_kara_lee.png" alt="Kara Lee network"/>
</div>

<p>To understand how to query the network, it's easier to focus on the factor
graph. In the factor graph, there is a factor for all ground formulas, and all
the ground predicates found in the ground formula are linked to the factor:</p>

<div class="imagecenter">
  <img src="../images/mln_kara_lee_factors.png" alt="Kara Lee network"/>
</div>

<p>By applying \(\{Kara, Lee\}\) to our two formulas we got the ground formulas
</p>

\[Smoking(Kara) \Rightarrow Cancer(Kara), 1.5;\]
\[Smoking(Lee) \Rightarrow Cancer(Lee), 1.5;\]
\[Friend(Kara, Kara) \land Smoking(Kara) \Rightarrow Smoking(Kara), 1.1;\]
\[Friend(Kara, Lee) \land Smoking(Kara) \Rightarrow Smoking(Lee), 1.1;\]
\[Friend(Lee, Kara) \land Smoking(Lee) \Rightarrow Smoking(Kara), 1.1;\]
\[Friend(Lee, Lee) \land Smoking(Lee) \Rightarrow Smoking(Lee), 1.1;\]

<p>And you can see all the six ground formulas have a corresponding factor (the
squares) in the graph. From there, if we want to compute \(P(X = x)\), we use
the equation</p>

\[P(X = x) = \frac{1}{Z}\exp\left(\sum_i w_ig_i(x) \right),\]

<p>where \(w_i\) is the weight of the formula associated with the <i>i</i>th
factor, \(g_i\) equals 1 if the formula is true given the values of the
predicates or 0 if it's false, and \(Z\) is a normalizing constant, that is:
it's the sum of the values of all possible assignments:</p>

\[Z = \sum_{x' \in \ \mathcal{X}}\exp\left(\sum_i w_ig_i(x') \right),\]

<p>with \(\mathcal{X}\) being the set of possible assignments. Now, let's try
to compute the probability of Kara and Lee being mutual friend, neither of them
being friend with themselves, Kara smokes and has cancer, but Lee neither
smokes nor has cancer. We'll get the following network (green = true
predicates, red = false predicates):</p>

<div class="imagecenter">
  <img src="../images/mln_kara_lee_factors_ass_p1.png" alt="Kara Lee network"/>
</div>

<p>The value of the predicates can then be used to determine the factors that
are true (worth 1, in green) and those that are false (worth 0, in red):</p>

<div class="imagecenter">
  <img src="../images/mln_kara_lee_factors_ass_p2.png" alt="Kara Lee network"/>
</div>

<p>If you are confused about how factors are resolved, it's probably because
you misinterpret the logic symbol implies \(\Rightarrow\),
<a href='2015-07-13-fol.html'>check here for clarifications</a>. For example,
the factor for \(Smoking(Lee) \Rightarrow Cancer(Lee)\) is true, because
\(False \Rightarrow x\) returns true regardless of whether <i>x</i> is true or
false.</p>

<p>With the factors resolved, we can compute the probability:</p>

\[\frac{1}{Z}\exp\left(1 \times 1.1 + 1 \times 1.1 + 1 \times 1.1 + 0 \times 1.1 + 1 \times 1.5 + 1 \times 1.5\right),\]
\[\frac{1}{Z}\exp\left(3 \times 1.1 + 2 \times 1.5\right),\]
\[\frac{544.57}{Z}.\]

<p>The normalizing constant is \(Z = 229210.5024\), so our probability
is:</p>

\[\frac{544.57}{229210.5024} = 0.0023759.\]

<p>If we were to flip Cancer(Kara) to false, we'd get a lower probability (because smoking causes cancer):</p>

\[\frac{1}{Z}\exp\left(3 \times 1.1 + 1 \times 1.5\right) = \frac{121.51}{229210.5024} = 0.00053012.\]

<h2>Code Example</h2>

<p>In this section we'll perform an exact inference on a few MLNs. If you want
to follow the examples, you can copy the library with:</p>

<div class='terminal'><pre>
$ git clone https://github.com/PhDP/Faun.git
$ cd Faun
$ cabal install
</pre></div>

<p>The code is tested on both Linux and Windows, and it should work fine on OSX
with the <a href='https://www.haskell.org/platform/'>Haskell platform
installed</a>. Right now, it performs only exact inference, which is useful for
tests...  but it does not scale since the Markov networks generated by Markov
logic are humongous even with a few constants. Hopefully there are many good
algorithms for inference, but for now they are not sufficiently tested in
Faun. Anyway, exact inference will be enough for exploring a few
models.</p>

<p>First, we launch an interactive console from the root of the code:</p>

<div class='terminal'><pre>
$ cabal repl
</pre></div>

<p>Then, we'll load the Markov logic network module:</p>

<pre><code class="haskell">ghci> import Faun.MarkovLogic</code></pre>

<p>The most straightforward way to build a Markov logic network is with
<i>fromStrings</i>. This function takes an array of strings, each of which must
be a valid first-order logic formula followed (or preceded) by a number (the
weight of the formula). In our smoking example we have:</p>

<pre><code class="haskell">ghci> let mln = fromStrings ["∀x Smoking(x) ⇒ Cancer(x) 1.5", "∀x∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y) 1.1"]</code></pre>

<p>The strings were copy-pasted from Richardson and Domingos' paper, but the
parsers is flexible and will accept a keyboard-friendly form too:</p>

<pre><code class="haskell">ghci> fromStrings ["1.5 forall x Smoking(x) implies Cancer(x)", "1.1 forall x, y Friend(x, y) and Smoking(x) implies Smoking(y)"]</code></pre>

<p>We can see the structure of the network simply by typing its name:</p>

<pre><code class="haskell">ghci> mln
1.5                     ∀x Smoking(x) ⇒ Cancer(x)
1.1                     ∀x ∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y)</code></pre>

<p>Since a Markov logic network is a template for Markov networks. To get a
Markov network, we need to apply a set of constant to the Markov logic networks
Following our example in the last section we'll use:</p>

<pre><code class="haskell">ghci> let cs = ["Elaine", "George", "Jerry"]</code></pre>

<p>Then, we can query the network, say, what is the probability that Jerry has
cancer?</p>

<pre><code class="haskell">ghci> ask mln cs "P(Cancer(Jerry))"
Just 0.6040175344121184</code></pre>

<p>The function <i>ask</i> takes a Markov logic network, a list
of terms (represented as a list of strings), and a string query. It will return
Just P, with P being a probability in the [0.0, 1.0] range, or Nothing if the
parser fails to read the query. To make the process a bit easier we'll create
a function <i>query</i> with the first two arguments supplied so we don't need to
repeat them ad nauseam:</p>

<pre><code class="haskell">ghci> let query = ask mln cs</code></pre>

<p>Then we can ask queries with this function:</p>

<pre><code class="haskell">ghci> query "P(Cancer(Jerry), Cancer(Elaine))"
Just 0.3696834237837972
ghci> query "P(Cancer(Jerry) | Smoking(Jerry))"
Just 0.8175744761936782
</code></pre>

<p>While the formulas look distinct in the Markov logic network, the fact that
they share predicates link them. So, even if there is no direct relationship
between friendship and cancer, we have:</p>

<pre><code class="haskell">ghci> query "P(Cancer(Jerry) | Smoking(Elaine))"
Just 0.6506081590969498
ghci> query "P(Cancer(Jerry) | Smoking(Elaine), Friend(Elaine, Jerry))"
Just 0.7043948532279771
</code></pre>

<p>...just as expected, because friends tend to smoke, so Elaine being Jerry's
friend increases the chance that Jerry is smoking, and if we know he doesn't
we'll get:</p>

<pre><code class="haskell">ghci> query "P(Cancer(Jerry) | Smoking(Elaine), Friend(Elaine, Jerry), !Smoking(Jerry))"
Just 0.4999999999999964
ghci> query "P(Cancer(Jerry) | !Smoking(Jerry))"
Just 0.5000000000000238
</code></pre>

<p>The cool thing with all of this is that we already have a rich structure for
inference from just two simple logical formulas, weights, and a list of objects
to ground the formulas.</p>

<p>We can add a logic formula to the network with the <i>tell</i> function. It
takes a string (just like <i>fromStrings</i> takes a list of strings), an
existing Markov logic network, and will return a new Markov logic network with
the formula added. Let's say we want to add a rule that <i>friends of friends are
friends</i>, we could add this rule with a weight of 2.0 with:</p>

<pre><code class="haskell">ghci> let mln' = tell "2.0 A.x,y,z Friend(x, y) and Friend(y, z) => Friend(x, z)" mln
ghci> mln'
1.5                     ∀x Smoking(x) ⇒ Cancer(x)
2.0                     ∀x ∀y ∀z Friend(x, y) ∧ Friend(y, z) ⇒ Friend(x, z)
1.1                     ∀x ∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y)</code></pre>

<p>We'll build an ask function for this network using the same constants
(Jerry, Elaine, George):</p>

<pre><code class="haskell">ghci> let query' = ask mln' cs</code></pre>

<p>Let's compare how our first MLN behaved compare to our new one:</p>

<pre><code class="haskell">ghci> query "P(Smoking(George) | Smoking(Jerry), Friend(Jerry, Elaine), Friend(Elaine, George))"
Just 0.5877406718485353
ghci> query' "P(Smoking(George) | Smoking(Jerry), Friend(Jerry, Elaine), Friend(Elaine, George))"
Just 0.7080082227672424
</code></pre>

<p>Same query, same information, but with a different model (the MLN), we get
different answers. Now, something is bugging me with the original model:</p>

<pre><code class="haskell">ghci> query "P(Cancer(Jerry) | Smoking(George))"
Just 0.6506081590969498
ghci> query "P(Cancer(Jerry) | Smoking(George), Friend(George, Jerry))"
Just 0.7043948532279771
ghci> query "P(Cancer(Jerry) | Smoking(George), Friend(Jerry, George))"
Just 0.6506081590968945
</code></pre>

<p>The problem is that friendship is assymmetricial in this MLN.  If we know
George is friend with Jerry, there's a very good chance that Jerry is friend
with George, and thus influenced by his smoking habit. The nice thing with
Markov logic is that all formulas are connected, so we can fix this issue by
adding a formula, our new Markov logic network is:</p>

\[\forall x: Smoking(x) \Rightarrow Cancer(x), 1.5;\]
\[\forall x, y: Friend(x, y) \land Smoking(x) \Rightarrow Smoking(y), 1.1;\]
\[\forall x, y: Friend(x, y) \iff Friend(y, x), 2.0;\]

<p>The last formula has the \(\iff\) operator, which is true either when both
sides are true, or when both sides are false. Thus, this formula says: if \(x\)
is friend with \(y\), then \(y\) is friend with \(x\), and if \(x\) is not friend
with \(y\), then \(y\) is not friend with \(x\). Since it's probabilistic, it doesn't
need to be true all the time, but I give it a fairly high weight. And now we have:</p>

<pre><code class="haskell">ghci> let mln'' = tell "ForAll x, y: Friend(x, y) iff Friend(y, x) 2.0" mln
ghci> mln''
1.5                     ∀x Smoking(x) ⇒ Cancer(x)
1.1                     ∀x ∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y)
2.0                     ∀x ∀y Friend(x, y) ⇔ Friend(y, x)
ghci> let query'' = ask mln'' cs
ghci> query'' "P(Cancer(Jerry) | Smoking(George))"
Just 0.6506081590969105
ghci> query'' "P(Cancer(Jerry) | Smoking(George), Friend(George, Jerry))"
Just 0.7043948532279295
ghci> query'' "P(Cancer(Jerry) | Smoking(George), Friend(Jerry, George))"
Just 0.7018023327893508
</code></pre>

<p>Again, with the same information, the same query, just by adding a simple
formula we were able to get a richer model. Of course, there's much more to
Markov logic networks than simple inference, we can learn new formulas from
data, combine existing knowledge bases, transfer knowledge between domains...</p>

]]></summary>
</entry>
<entry>
    <title>A crash course in first-order logic</title>
    <link href="http://phdp.github.io//posts/2015-07-13-fol.html" />
    <id>http://phdp.github.io//posts/2015-07-13-fol.html</id>
    <published>2015-07-13T00:00:00Z</published>
    <updated>2015-07-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>A crash course in first-order logic</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="A crash course in first-order logic" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2015.07.13
</p>

<p>This is a short but reasonably complete description of first-order logic, a
rich system to reason about objects and their relationships. I care mostly
about first-order logic for its role in statistical relational learning (a
branch of machine learning), <a href='2015-07-13-srl-code.html'>which I'll
cover in another post</a>. If you want a more detailed explanation, see <a
href='http://aima.cs.berkeley.edu/'>Russell and Norvig's excellent A.I.
book.</a></p>

<h2>Terms</h2>

<p>Terms represent objects and relationships between objects, they are the
reason why first-order logic is so flexible. There are three types of
terms:</p>

<ol type='I'>
  <li><b>Constants</b> represent objects, e.g.: <i>Tokyo</i>, the number <i>47</i>, <i>Cylon</i>, <i>Lion</i>.</li>
  <li><b>Variables</b> range over objects, e.g. the variable <i>c</i> could represent a city, <i>x</i> an integer, <i>s</i> a species. By convention, variables will start with a lowercase character (it's not a universal convention, in fact it's common to have the opposite).</li>
  <li><b>Functions</b> map lists of terms to a term, e.g. <i>CapitalOf</i> could take a country and return a city, while <i>Multiply</i> takes two numbers and returns a number.</li>
</ol>

<p>Example:</p>

\[Add(x, 5).\]

<p><i>Add</i> is a function taking two numbers and returning a number, <i>x</i>
is a variable, and 5 is a constant. Since a function is a term, it can be used
within functions:</p>

\[Add(Multiply(x, y), 5).\]

<h2>Predicates</h2>

<p>First-order logic formulas ultimately resolve to a truth value: True or
False, yet the terms we've seen can represent cities, numbers, pretty much
anything. To get a truth value, we need predicates. A predicate is like a
function but it maps terms to a truth value instead of mapping them to a term.
For example, if we want to say that adding 0 to <i>x</i> yields <i>x</i>, we
can write:</p>

\[Equals(Add(x, 0), x).\]

<p>It's common to use the equal sign for the "equals" (or identity) predicate:</p>

\[Add(x, 0) = x.\]

<p><i>Equals</i> is a predicate. In this case it takes two numbers and returns
true or false. We could have a predicate taking three cities and return
true if they are on the same continent:</p>

\[SameContinent(Toronto, c, CapitalOf(LargestCountryOf(Europe))),\]

<p>where <i>SameContinent</i> is a predicate, <i>Toronto</i> and <i>Europe</i>
are constants, <i>c</i> a variable ranging over cities, and both
<i>CapitalOf</i> and <i>LargestCountryOf</i> are functions taking a single
argument.</p>

<h2>Atomic formulas</h2>

<p>An atomic formula is something that, alone, is a valid first-order logic formula. A predicate
is an atomic formula since it returns a truth value, but we also have two special symbols: True and False.</p>

<p><b>True</b> is also called <i>top</i>, and can be represented with the symbol \(\top\) or just T.</p>

<p><b>False</b> is also called <i>bottom</i>, and can be represented with the symbol \(\bot\) or just F.</p>

<h2>Connectives</h2>

<p>You can connect formulas with connectives to form complex formulas. The
standard connectives are:</p>

<ol style='list-style-type: upper-roman'>
  <li>The binary connective <b>and</b>: \(x \land y\), which is true only if both \(x\) and \(y\) are true. Like all other connectives shown here, if \(x\) and \(y\) are valid formulas, then \(x \land y\) is also a valid formula.</li>
  <li>The binary connective <b>or</b>: \(x \lor y\), which is true only if \(x\) is true, if \(y\) is true, or if both are true.</li>
  <li>The binary connective <b>implies</b>: \(x \Rightarrow y\), returns true in all cases, except if \(x\) is true and \(y\) is false.</li>
  <li>The binary connective <b>iff</b>: \(x \iff y\), returns true if \(x\) and \(y\) have the same value, that is if they are both true, or both false.</li>
  <li>The binary connective <b>xor</b> (exclusive or): \(x \oplus y\), returns true if \(x\) and \(y\) have different values.</li>
  <li>The unary connective <b>not</b>: \(\lnot x\), which is true only if \(x\) is false.</li>
</ol>

<p>Be careful with implication, there is nothing wrong with it, except that it
doesn't fit how we use the term <i>implies</i>. For example:
\(AgeOf(Earth) = 42 \Rightarrow StillAlive(Elvis)\) is true. If you're
confused, read again the description of <b>implies</b>. Here's the truth
table for the binary connectives:</p>

<table style='width: 100%; text-align:center;'>
  <tr>
    <th>Connective</th>
    <th>Informal name</th>
    <th>Symbol</th>
    <th>T x T</th><th>T x F</th><th>F x T</th><th>F x F</th>
  </tr>
  <tr>
    <td>Conjunction</td>
    <td>and</td>
    <td>\(\land\)</td>
    <td>T</td><td>F</td><td>F</td><td>F</td>
  </tr>
  <tr>
    <td>Disjunction</td>
    <td>or</td>
    <td>\(\lor\)</td>
    <td>T</td><td>T</td><td>T</td><td>F</td>
  </tr>
  <tr>
    <td>Implication</td>
    <td>implies</td>
    <td>\(\Rightarrow\)</td>
    <td>T</td><td>F</td><td>T</td><td>T</td>
  </tr>
  <tr>
    <td>Equivalence</td>
    <td>iff</td>
    <td>\(\leftrightarrow\)</td>
    <td>T</td><td>F</td><td>F</td><td>T</td>
  </tr>
  <tr>
    <td>Exclusive disjunction</td>
    <td>xor</td>
    <td>\(\veebar\)</td>
    <td>F</td><td>T</td><td>T</td><td>F</td>
  </tr>
</table>

<h2>Quantifiers</h2>

<p>There are two main quantifiers in first-order logic: the universal
quantifier "for all" denoted \(\forall\), and the existential quantifier
"exists" denoted \(\exists\). They, well, quantify variables, e.g.:</p>

\[\forall x: Multiply(x, 0) = 0\]

<p>reads "for all x, multiplying x by 0 yields 0". Another example:</p>

\[\forall x: Real(x) \Rightarrow (\exists y: y > x)\]

<p>which means, "for all real numbers x, there is a number y that is greater
than x". Note that both \(Real\) and the &gt; sign are predicates.</p>

<p>Another example: we can express "there is a color c brighter than x, unless x
is white" with:</p>

\[\forall x: IsWhite(x) \lor (\exists c: BrighterThan(c, x)).\]

<p>Often, it is useful to add a "unique" quantifier denoted \(\exists!\), for
example to say there is a one and only one successor to any integer:</p>

\[\forall x \in \mathbb{Z}: \exists! y \in \mathbb{Z}: y = x + 1.\]

<p>Where (\in\) reads "belongs to" and \(\mathbb{Z}\) refers to positive or negative integers.</p>

]]></summary>
</entry>
<entry>
    <title>Automated reasoning in F#, Scala, Haskell, C++, and Julia</title>
    <link href="http://phdp.github.io//posts/2015-04-05-automated-reasoning.html" />
    <id>http://phdp.github.io//posts/2015-04-05-automated-reasoning.html</id>
    <published>2015-04-05T00:00:00Z</published>
    <updated>2015-04-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Automated reasoning in F#, Scala, Haskell, C++, and Julia</h1>

<a href="https://twitter.com/share" class="twitter-share-button" data-text="Automated reasoning in F#, Scala, Haskell, C++, and Julia" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  2015.04.05
</p>

<p>We need to simplify the following expression:</p>

\[e = (1 + 0 \times x) \times 3 + 12.\]

<p>Luckily for us, we won't have to remember any elementary school arithmetic,
because Harris' excellent <a
  href='http://www.cambridge.org/ca/academic/subjects/computer-science/programming-languages-and-applied-logic/handbook-practical-logic-and-automated-reasoning'>
  <i>Handbook of Practical Logic and Automated Reasoning</i></a> begins with a
simple algorithm to do exactly that. It's not complicated, but it's a pretty
good barometer of how painful a programming language will be for the kind of
hybrid (probabilistic logic, or statistical relational) approaches I work with.
Here, I compare the implementations of Harris' simple algorithm in F#, Scala,
Haskell, C++, and Julia.</p>

<p>No programming languages were hurt while writing this post. It's not a
competition, and I avoided talking about languages I dislike. Sum types are
discussed in length because they are awesome and useful for this problem
(and many, many others).</p>

<h2>The ML family</h2>

<p>Harris' book uses OCaml, a popular language for solvers. F#, Haskell, and
Scala all share roots with OCaml, with F# being the closest thing to an OCaml
dialect. I'll start with F#:</p>

<pre><code class="fsharp">/// A sum type for the expression.
/// An expression is either a var (which is a string), a constant
/// (which is an integer), an addition (made of two expressions)
/// or a multiplication (also made of two expressions).
type Expr =
    | Var of string
    | Const of int
    | Add of Expr * Expr
    | Mul of Expr * Expr

/// Simplify a single component of the expression. This function
/// takes an expression and use pattern matching to select the
/// right approach based on type and value. For example, if we
/// add a constant 0 to some x (which can be expression), then
/// we return x.
let simplify1 e =
    match e with
    | Add (Const 0, x)
    | Add (x, Const 0)
    | Mul (x, Const 1)
    | Mul (Const 1, x)        -> x
    | Mul (x, Const 0)
    | Mul (Const 0, x)        -> Const 0
    | Add (Const a, Const b)  -> Const (a + b)
    | Mul (Const a, Const b)  -> Const (a * b)
    | _                       -> e

/// Recursive function to simplify an entire expression.
let rec simplify e =
    match e with
    | Add (x, y) -> Add (simplify x, simplify y)
    | Mul (x, y) -> Mul (simplify x, simplify y)
    | _          -> e
    |> simplify1

/// Return the value string if the expression can be reduced to a constant.
let exprStr e =
    match e with
    | Const x -> string x
    | _       -> "The expression could not be simplified to a constant."

/// The |> operator sends the result on its left to its right, for example
/// "5.0 |> log |> sqrt" computes log(5.0) and then the square root of the
/// result. This is nice because it allows a more natural left-to-right
/// flow for functional programming.
[&lt;EntryPoint>]
let main argv =
    Add (Mul (Add (Const 1, Mul (Const 0, Var "x")), Const 3), Const 12)
    |> simplify
    |> exprStr
    |> printf "%s"
    0 /// F#'s main returns 0 for success à la C
</code></pre>

<p>It's almost the same as the OCaml version in Harris' book. The key trick is
to define an expression (Expr) as a variable (string) <b>or</b> a constant
(integer) <b>or</b> an addition <b>or</b> a multiplication (both made of two
expressions). The <b>or</b> is important, object-oriented programming languages
focuses on hierarchies of objects, while sum types define a type as a series of
alternatives. Sum types are important for another reason: they provide
an easy way to express things like "this function <i>might</i> return
an integer", for example in Haskell if we want a data structure that maps
keys to values:</p>

<pre><code class="haskell">import Data.Map (Map)
import qualified Data.Map as Map

capitals = Map.fromList [("Finland", "Helsinki"), ("France", "Paris"),
  ("Japan", "Tokyo"), ("South Korea", "Seoul"), ("Arrakis", "Arrakeen")]

lookupCapitals country = case Map.lookup country capitals of
  Just capital -> "The capital of " ++ country ++ " is " ++ capital ++ "."
  Nothing      -> "Is " ++ country ++ " even a country?"
</code></pre>

<p>The point is that a key-value store will only return a value if the key is
present. In this example, the map takes a country (string) and returns its
capital (string). However, when we try to take a value from the map with the
lookup function, Haskell returns a <b>Maybe</b> type with either <b>Just
String</b>, if the string provided is found in the map, or <b>Nothing</b> if
the key is absent. We then use pattern matching to deal with these
possibilities in the lookupCapitals function. One of the most common mistake in
programming is to return a null and not deal with it properly. The solution
with sum types is to return a wrapped value and handling possibilities
explicitly with pattern matching. It solves with types what many languages
would solve with exceptions and try-catch apparatuses.</p>

<pre><code class="haskell">ghci> lookupCapitals "Arrakis"
"The capital of Arrakis is Arrakeen."
ghci> lookupCapitals "Canada"
"Is Canada even a country?"</code></pre>

<p>Speaking of Haskell, the code for the algorithm is:</p>

<pre><code class="haskell">data Expr =
    Var String
  | Const Int
  | Add Expr Expr
  | Mult Expr Expr

simplify1 :: Expr -> Expr
simplify1 e = case e of
  Add (Const 0) x           -> x
  Add x (Const 0)           -> x
  Add (Const a) (Const b)   -> Const $ a + b
  Mult x (Const 0)          -> Const 0
  Mult (Const 0) x          -> Const 0
  Mult x (Const 1)          -> x
  Mult (Const 1) x          -> x
  Mult (Const a) (Const b)  -> Const $ a * b
  _                         -> e

simplify :: Expr -> Expr
simplify e = case e of
  Add x y   -> simplify1 $ Add (simplify x) (simplify y)
  Mult x y  -> simplify1 $ Mult (simplify x) (simplify y)
  _         -> simplify1 e

e = Add (Mult (Add (Const 1) (Mult (Const 0) (Var "x"))) (Const 3)) (Const 12)
s = simplify e

main = putStrLn $ case s of
  Const x -> show x
  _ -> "Could not simplify the expression to a constant."
</code></pre>

<p>It's quite similar to F#. I decided to add types explicitly to
<i>simplify1</i> and <i>simplify</i>, but Haskell is smart enough to deduce the
type without this. Arguably the only thing worth explaining is the $ operator.
The operator forces Haskell to evaluate the expression to the right of the
operator in priority, and if it reminds you of parentheses, you are absolutely
right. <i>x</i> and <i>y</i> have the same value here:</p>

<pre><code class="haskell">x = log (sqrt (exp 5.0))
y = log $ sqrt $ exp 5.0
</code></pre>

<p>The operator is there to reduce visual clutter. In my opinion, F# is easier
to read because the |> operator enforces left-to-right reading, which is more
natural than reading code inside-out:</p>

<pre><code class="fsharp">let z = exp 5.0 |> sqrt |> log</code></pre>

<p>Although it's trivial to simulate this operator in Haskell:</p>

<pre><code class="haskell">(|>) :: t0 -> (t0 -> t1) -> t1
(|>) x f = f x

-- Now valid Haskell:
z = exp 5.0 |> sqrt |> log</code></pre>

<p>And now for something a bit different: Scala. It's also a static
functional programming language with sum types, but its greater
integration with the object-oriented paradigm is evident:</p>

<pre><code class="scala">object Simplify {
  sealed abstract class Expr { override def toString = show(this) }
  case class Variable(name: String) extends Expr
  case class Const(value: Int) extends Expr
  case class Add(left: Expr, right: Expr) extends Expr
  case class Mult(left: Expr, right: Expr) extends Expr

  def evalOne(e: Expr): Expr = e match {
    case Add(Const(0), r)         => r
    case Add(l, Const(0))         => l
    case Add(Const(a), Const(b))  => Const(a + b)
    case Mult(Const(0), r)        => Const(0)
    case Mult(l, Const(0))        => Const(0)
    case Mult(Const(1), r)        => r
    case Mult(l, Const(1))        => l
    case Mult(Const(a), Const(b)) => Const(a * b)
    case _                        => e
  }

  def eval(e: Expr): Expr = e match {
    case Add(l, r)  => evalOne(Add(eval(l), eval(r)))
    case Mult(l, r) => evalOne(Mult(eval(l), eval(r)))
    case _          => e
  }

  def show(e: Expr) = e match {
    case Const(x) => print(x)
    case _        =>
      print("The expression could not be simplified to a constant.")
  }

  def main(args: Array[String]) {
    var e = Add(Mult(Add(Const(1), Mult(Const(0), Variable("x"))),
              Const(3)), Const(12))
    var s = eval(e)
    print(s)
  }
}
</code></pre>

<p>Everything is an object in Scala. Thus, we have to define the functions to
simplify as methods inside a singleton object. I named the functions
<i>evalOne</i> and <i>eval</i> since it has a bit odd to have a function named
<i>simplify</i> inside a Simplify object.</p>

<h2>C++</h2>

<p>Few understand every corner of C++'s monstrous standard. It's huge.  Surely,
with so many features, there must something to solve this
simple problem cleanly.  Well... no. It's a well-known lacuna with C++,
see <a href="https://parasol.tamu.edu/~yuriys/pm/"><i>Open and
Efficient Type Switch for C++</i></a> for a library built to implement
pattern matching (the effort is directed by the creator
of the C++ language). That said, here I'll use the boost library (A)
because solutions based only on the standard library are contrived and
(B) because boost is almost standard, and I don't want to rely on third-party
libraries.</p>

<pre><code class="cpp">#include &lt;iostream&gt;
#include &lt;string&gt;
#include &lt;boost/variant.hpp&gt;

// Forward declarations:
struct add;
struct mult;

// The variant for the expression:
using expr = boost::variant&lt;
  int,
  std::string,
  boost::recursive_wrapper&lt;add&gt;,
  boost::recursive_wrapper&lt;mult&gt;&gt;;

// A base class for all binary operations:
class binary_op {
  expr m_left, m_right;

public:
  // Builds a binary operation from left and right expressions.
  binary_op(expr const& left, expr const& right)
    : m_left(left), m_right(right) {
  }

  // Returns the expression to the left side of the expression.
  auto left() const -&gt; expr const& {
    return m_left;
  }

  // Returns the expression to the right side of the expression.
  auto right() const -&gt; expr const& {
    return m_right;
  }
};

// Defines the 'add' operator.
struct add : public binary_op {
  add(expr const& left, expr const &right)
    : binary_op(left, right) {
  }
};

// Defines the 'mult' operator.
struct mult : public binary_op {
  mult(expr const& left, expr const &right)
    : binary_op(left, right) {
  }
};

// Overload * and + to simplify creating expressions.

auto operator+(expr const& lhs, expr const& rhs) -&gt; expr {
  return add{lhs, rhs};
}

auto operator*(expr const& lhs, expr const& rhs) -&gt; expr {
  return mult{lhs, rhs};
}

// A visitor for addition.
struct add_visit : public boost::static_visitor&lt;expr&gt; {
  auto operator()(int lhs, int rhs) const -&gt; expr {
    return expr{lhs + rhs};
  }

  template&lt;typename R&gt;
  auto operator()(int lhs, R const& rhs) const -&gt; expr {
    return lhs == 0? expr{rhs} : add{expr{lhs}, expr{rhs}};
  }

  template&lt;typename L&gt;
  auto operator()(L const& lhs, int rhs) const -&gt; expr{
    return rhs == 0? expr{lhs} : add{expr{lhs}, expr{rhs}};
  }

  template&lt;typename L, typename R&gt;
  auto operator()(L const& lhs, R const& rhs) const -&gt; expr {
    return add{expr{lhs}, expr{rhs}};
  }
};

// A visitor for multiplication.
struct mul_visit : public boost::static_visitor&lt;expr&gt; {
  auto operator()(int lhs, int rhs) const -&gt; expr {
    return expr{lhs * rhs};
  }

  template&lt;typename R&gt;
  auto operator()(int lhs, R const& rhs) const -&gt; expr {
    return lhs == 0?
      expr{0} : (lhs == 1? expr{rhs} : mult{expr{lhs}, expr{rhs}});
  }

  template&lt;typename L&gt;
  auto operator()(L const& lhs, int rhs) const -&gt; expr {
    return rhs == 0?
      expr{0} : (rhs == 1? expr{lhs} : mult{expr{rhs}, expr{lhs}});
  }

  template&lt;typename L, typename R&gt;
  auto operator()(L const& lhs, R const& rhs) const -&gt; expr {
    return mult{expr{lhs}, expr{rhs}};
  }
};

struct simplify1 : public boost::static_visitor&lt;expr&gt; {
  auto operator()(add const& a) const -&gt; expr {
    return boost::apply_visitor(add_visit{}, a.left(), a.right());
  }

  auto operator()(mult const& m) const -&gt; expr {
    return boost::apply_visitor(mul_visit{}, m.left(), m.right());
  }

  template&lt;typename T&gt;
  auto operator()(T const& t) const -&gt; expr {
    return expr{t};
  }
};

struct simplify : public boost::static_visitor&lt;expr&gt; {
  auto operator()(add const& a) const -&gt; expr {
    auto left = boost::apply_visitor(simplify{}, a.left());
    auto right = boost::apply_visitor(simplify{}, a.right());
    auto add_lr = boost::apply_visitor(add_visit{}, left, right);
    return boost::apply_visitor(simplify1{}, add_lr);
  }

  auto operator()(mult const& m) const -&gt; expr {
    auto left = boost::apply_visitor(simplify{}, m.left());
    auto right = boost::apply_visitor(simplify{}, m.right());
    auto mul_lr = boost::apply_visitor(mul_visit{}, left, right);
    return boost::apply_visitor(simplify1{}, mul_lr);
  }

  template&lt;typename T&gt;
  auto operator()(T const& t) const -&gt; expr {
    return expr{t};
  }
};

struct print_expr : public boost::static_visitor&lt;std::string&gt; {
  auto operator()(int n) const -&gt; std::string {
    return std::to_string(n);
  };

  auto operator()(expr const&) const -&gt; std::string {
    return "The expression could not be simplified to a constant.";
  };
};

auto main() -&gt; int {
  const auto e = (expr{1} + expr{0} * expr{"x"}) * expr{3} + expr{12};
  const auto s = boost::apply_visitor(simplify{}, e);
  std::cout &lt;&lt; boost::apply_visitor(print_expr{}, s) &lt;&lt; std::endl;
  return 0;
}</code></pre>

<p>This is boost::variant in action. My biggest qualm with this type of clever
header-heavy code is that you get to see a big chunk of the developers'
lifework unroll before your eyes every time a small mistake is made. Otherwise
it's an OK substitute for proper sum types/pattern matching. If you want to know
how this code works, you need to read a bit on the visitor pattern.</p>

<h2>Julia</h2>

<p>Julia is an attempt to build a fast and flexible replacement for
R/Python/Matlab.  An issue with most dynamic languages is that there is no
elegant way to switch on type. To be fair, you cannot really do it with most
static languages either, see previous section... However, Julia supports
multiple-dispatch based on type annotation. To be clear, it's quite different
from the F#/Scala/Haskell approach.  In these languages, it is possible to define
sum types and do pattern matching on their constructors. With Julia, we define a
function with type annotation and let the interpreter dispatch based on runtime
type information. Multiple dispatch is supported in Julia for performance: it
allows the interpreter to compile optimized functions and use the best one,
adding predictability while keeping the language dynamic (for some reason...).
Here's the algorithm in Julia:</p>

<pre><code class="julia">abstract Expr

type Const <: Expr; val::Int end
type Var <: Expr; name::String end
type Add <: Expr; left::Expr; right::Expr end
type Mult <: Expr; left::Expr; right::Expr end

add(x::Const, y::Const) = Const(x.val + y.val)
add(x::Const, y::Expr) = x.val == 0? y : Add(x, y)
add(x::Expr, y::Const) = add(y, x)
add(x::Expr, y::Expr) = Add(x, y)

mult(x::Const, y::Const) = Const(x.val * y.val)
mult(x::Const, y::Expr) = x.val == 1? y : (x.val == 0? Const(0) : Mult(x, y))
mult(x::Expr, y::Const) = mult(y, x)
mult(x::Expr, y::Expr) = Mult(x, y)

simplify1(a::Add) = add(a.left, a.right)
simplify1(m::Mult) = mult(m.left, m.right)
simplify1(e::Expr) = e

simplify(a::Add) = simplify1(Add(simplify(a.left), simplify(a.right)))
simplify(m::Mult) = simplify1(Mult(simplify(m.left), simplify(m.right)))
simplify(e::Expr) = e

printExpr(c::Const) = print(c.val)
printExpr(e::Expr) =
  print("The expression could not be simplified to a constant.")

e = Add(Mult(Add(Const(1), Mult(Const(0), Var("x"))), Const(3)), Const(12))
s = simplify(e)
printExpr(s)
</code></pre>

<p>Unlike pattern matching, we can only dispatch on type, so we need an if
expression (the ? operator in Julia, just like C), or I could've used the match
macro, but it's overkill here. It's not too inelegant, and at first I thought
it was a good enough way to simulate sum types and pattern matching. It matters
to the Julia ecosystem because these features are very useful to build solvers,
logic and theorem proving systems, etc etc. Pretty nice for a technical
computing platform. Unfortunately, while Julia does well with this simple example,
I think an oddity with the language would soon bite us: return type declarations
are not allowed, and yes, it <i>is</i> a big deal.</p>

<p>First, it's a question of correctness: you can return a float thinking
you're returning an integer. That's awful. Also, since annotation is not
allowed for the return value, it's also impossible to add annotation for a
higher-order function (a function taking functions as input). As a concrete
example, first-order logic has <i>predicates</i> mapping objects to a boolean,
and <i>functions</i> mapping objects to objects. We'd like to do:</p>

<pre><code class="julia">solve(pre::(Object -> Bool), ...)

solve(fun::(Object -> Object), ...)
</code></pre>

<p>But instead, we'd have to test the type of the return value inside the
function. That said, Julia is young and <a
href='https://github.com/JuliaLang/julia/issues/1090'>it might get return type
declarations at some point.</a></p>

<h2>Conclusion</h2>

<p>Sum types and pattern matching are awesome.</p>


]]></summary>
</entry>

</feed>
